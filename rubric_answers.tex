\documentclass{article}
\usepackage[margin=0.75in]{geometry}
\usepackage{listings}
\usepackage{upquote}

\author{Caroline}
\title{Data Wrangle OpenStreetMaps Data}

\begin{document}
    \maketitle
    \section{Problems Encountered in the Map}
        The first problem I encountered was that even very simple code was
        taking a long time to run and using a lot of memory. I discovered that
        the \texttt{iterparse} function still builds an entire tree in memory unless
        you clear the elements after processing them.
    \section{Overview of the Data}
        \subsection{Output from initial cleaning programs}
            \subsubsection{}
            The \texttt{count\_tags.py} program output was
            \begin{lstlisting}
            {'bounds': 1,
             'member': 14358,
             'nd': 2376169,
             'node': 1926749,
             'osm': 1,
             'relation': 1145,
             'tag': 750748,
             'way': 262715}
            \end{lstlisting}

            \subsubsection{}
            First I ran the \texttt{count\_key\_types.py} as written for the
            exercise, and the output was
            \begin{lstlisting}
            [('lower', 443987), ('lower_colon', 294418), ('other', 12343)]
            \end{lstlisting}
            This means that there were no ``problematic characters'', however,
            there were quite a few keys of type ``other'', which could mean many
            different things. There could be uppercase characters, non-ascii
            characters, multiple colons in a single field name, or other strange
            characters not listed in the problematic characters set.

            To investigate this, I updated \texttt{count\_key\_types.py} to
            break down ``other'' into more detailed categories.
        \subsection{Output from Mongo queries on cleaned data}
    \section{Other Ideas about the Datasets}

\end{document}
