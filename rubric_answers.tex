\documentclass{article}
\usepackage[margin=0.75in]{geometry}
\usepackage{listings}
\usepackage{upquote}
\usepackage{parskip}

\author{Caroline}
\title{Data Wrangle OpenStreetMaps Data}

\begin{document}
    \maketitle
    \section{Problems Encountered in the Map}
        I began by running the street name auditing that I wrote for the Lesson
        6 exercise, and I found a handful of abbreviated or misspelled street
        suffixes (e.g. ``Ave'' or ``Avnue'' instead of ``Avenue''). Based on
        these, I created the file \texttt{street\_mapping.json} to map ``messy''
        street names to clean ones, and later applied this mapping.

        While looking at street suffixes, I noticed some that were not
        capitalized, which made me think of checking capitalization in general.
        I wrote a function to normalize the captalization of names, and while I
        was at it, I normalized the whitespace as well. Then I checked which
        street names would be changed by this modification, and based on the
        results I rewrote the function until normalizing street names would
        improve any street name that it changed. Once this was done, I performed
        the normalization. Under this normalization, \verb"' Albert Sabin Way'"
        was changed to \verb"'Albert Sabin Way'" and \verb"'hamilton Avenue'"
        was changed to \verb"'Hamilton Avenue'". I applied normalization before
        fixing street suffixes so that I would not have to include lowercase
        street suffixes in my mapping.

    \section{Overview of the Data}
        \subsection{Output from initial cleaning programs}
            \subsubsection{}
            The \texttt{count\_tags.py} program output was
            \begin{lstlisting}
            {'bounds': 1,
             'member': 14358,
             'nd': 2376169,
             'node': 1926749,
             'osm': 1,
             'relation': 1145,
             'tag': 750748,
             'way': 262715}
            \end{lstlisting}

            \subsubsection{}
            First I ran the \texttt{count\_key\_types.py} as written for the
            exercise, and the output was
            \begin{lstlisting}
            [('lower', 443987), ('lower_colon', 294418), ('other', 12343)]
            \end{lstlisting}
            This means that there were no ``problematic characters'', however,
            there were quite a few keys of type ``other'', which could mean many
            different things. There could be uppercase characters, non-ascii
            characters, multiple colons in a single field name, or other strange
            characters not listed in the problematic characters set.

            To investigate this, I updated \texttt{count\_key\_types.py} to
            include unicode lowercase characters within the ``lower'' and
            ``lower\_colon'' classes, and I added the classes
            ``alpha\_with\_upper'' for keys with only letters and underscores,
            but at least one uppercase, and ``word\_plus\_colon'' for keys
            containing alphanumeric characters, underscores, and colons. I also
            modified ``lower\_colon'' to accept multiple colons. After this, the
            program output was 
            \begin{lstlisting}
            [('lower', 443987),
             ('lower_colon', 295889),
             ('word_plus_colon', 10459),
             ('alpha_with_upper', 373),
             ('other', 40)]
            \end{lstlisting}
            Thus, it looks like most of the ``other'' keys were keys that
            contained some mix of letters, numbers, underscores, and colons.
            
            Since at this point there were only 40 ``other'' keys left, I
            decided to print them out, and it turned out all of them contained
            hyphens.

            \subsubsection{}
            By running \texttt{find\_users.py}, I determined that 536 unique
            users have contributed to the Cincinnati data.
        \subsection{Output from Mongo queries on cleaned data}
    \section{Other Ideas about the Datasets}

\end{document}
